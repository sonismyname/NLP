{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_with_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YSWViCN635g8",
        "r96cK-kAVLbG",
        "sQKjqurFVY0u"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihl1YwMaRRum"
      },
      "source": [
        "# Sequence to Sequence attention model for machine translation\n",
        "\n",
        "This notebook trains a sequence to sequence (seq2seq) model with two dot product attention implemented for Spanish to English translation.\n",
        "\n",
        "The codes are built on TensorFlow Core tutorials: https://www.tensorflow.org/tutorials/text/nmt_with_attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfbpjs2fgzuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a8e64fb-035b-47a6-cbf1-cf7e35f78447"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOsMShvlg4ua"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Load data set\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDa3tH1hRyNq"
      },
      "source": [
        "*   Clean the sentences by removing special characters.\n",
        "*   Add a start and end token to each sentence.\n",
        "*   Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
        "*   Pad each sentence to a maximum length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwlD7yEZhM72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50dd0e91-04a2-460e-ff7c-a7113fb59bb2"
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n",
            "2654208/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKjEWl6WhZyk"
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s) #normalization form D\n",
        "      if unicodedata.category(c) != 'Mn') #Nonspacing Mark\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip()) # Lower and strip\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w) # add space\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\",\"¿\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  # remove extra space\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygKw5K_qrEGT",
        "outputId": "51bf0ac9-8a3f-4480-e673-39c076561f49"
      },
      "source": [
        "print(unicode_to_ascii('Ślusàrski'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slusarski\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc58-K0XhdCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac925bc-8045-4328-e4b4-2fe068ece391"
      },
      "source": [
        "en_sentence = u\"May I borrow this @ book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "<start> ¿ puedo tomar prestado este libro ? <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hw9ct4OhsRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede2c83d-7a36-481e-c177-e195b814a568"
      },
      "source": [
        "# Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs)\n",
        "\n",
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])\n",
        "print(len(en), len(sp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n",
            "118964 118964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCAYRuTlh5DY"
      },
      "source": [
        "# Tokenize the sentence into list of words(integers) and pad the sequence to the same length\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='') #filter lọc khỏi văn bản\n",
        "  lang_tokenizer.fit_on_texts(lang) #cập nhật từ vựng nội bộ\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang) # đưa sang vector integer\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e13Aa8yliFkp"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EasB_FLig5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7beee51c-4797-4e77-c1aa-5165b3779bae"
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "print(max_length_targ, max_length_inp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux7OPt3uxQgQ",
        "outputId": "d96af04c-c4a2-4f12-8aec-f3d85dafb414"
      },
      "source": [
        "inp_lang.word_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<start>': 1,\n",
              " '<end>': 2,\n",
              " '.': 3,\n",
              " 'tom': 4,\n",
              " '?': 5,\n",
              " '¿': 6,\n",
              " 'es': 7,\n",
              " 'no': 8,\n",
              " 'el': 9,\n",
              " 'a': 10,\n",
              " 'que': 11,\n",
              " 'me': 12,\n",
              " 'la': 13,\n",
              " 'de': 14,\n",
              " 'un': 15,\n",
              " 'esta': 16,\n",
              " 'se': 17,\n",
              " 'lo': 18,\n",
              " 'mi': 19,\n",
              " 'en': 20,\n",
              " 'una': 21,\n",
              " 'por': 22,\n",
              " 'te': 23,\n",
              " 'estoy': 24,\n",
              " 'ella': 25,\n",
              " 'yo': 26,\n",
              " '!': 27,\n",
              " 'eso': 28,\n",
              " 'le': 29,\n",
              " 'esto': 30,\n",
              " 'tu': 31,\n",
              " ',': 32,\n",
              " 'los': 33,\n",
              " 'aqui': 34,\n",
              " 'soy': 35,\n",
              " 'muy': 36,\n",
              " 'tengo': 37,\n",
              " 'puedo': 38,\n",
              " 'las': 39,\n",
              " 'gusta': 40,\n",
              " 'mary': 41,\n",
              " 'tiene': 42,\n",
              " 'son': 43,\n",
              " 'con': 44,\n",
              " 'como': 45,\n",
              " 'quien': 46,\n",
              " 'estaba': 47,\n",
              " 'su': 48,\n",
              " 'este': 49,\n",
              " 'favor': 50,\n",
              " 'estas': 51,\n",
              " 'eres': 52,\n",
              " 'quiero': 53,\n",
              " 'ellos': 54,\n",
              " 'fue': 55,\n",
              " 'bien': 56,\n",
              " 'casa': 57,\n",
              " 'ahora': 58,\n",
              " 'tomas': 59,\n",
              " 'donde': 60,\n",
              " 'mas': 61,\n",
              " 'estan': 62,\n",
              " 'nos': 63,\n",
              " 'he': 64,\n",
              " 'solo': 65,\n",
              " 'puede': 66,\n",
              " 'ha': 67,\n",
              " 'era': 68,\n",
              " 'todos': 69,\n",
              " 'al': 70,\n",
              " 'para': 71,\n",
              " 'ir': 72,\n",
              " 'tan': 73,\n",
              " 'todo': 74,\n",
              " 'estamos': 75,\n",
              " 'necesito': 76,\n",
              " 'ya': 77,\n",
              " 'nadie': 78,\n",
              " 'puedes': 79,\n",
              " 'trabajo': 80,\n",
              " 'voy': 81,\n",
              " 'usted': 82,\n",
              " 'tienes': 83,\n",
              " 'demasiado': 84,\n",
              " 'ese': 85,\n",
              " 'nada': 86,\n",
              " 'y': 87,\n",
              " 'hay': 88,\n",
              " 'mucho': 89,\n",
              " 'nunca': 90,\n",
              " 'hizo': 91,\n",
              " 'perro': 92,\n",
              " 'esa': 93,\n",
              " 'algo': 94,\n",
              " 'libro': 95,\n",
              " 'hoy': 96,\n",
              " 'poco': 97,\n",
              " 'dos': 98,\n",
              " 'parece': 99,\n",
              " 'todavia': 100,\n",
              " 'dinero': 101,\n",
              " 'tiempo': 102,\n",
              " 'nuevo': 103,\n",
              " 'sabe': 104,\n",
              " 'somos': 105,\n",
              " 'quiere': 106,\n",
              " 'mis': 107,\n",
              " 'gustan': 108,\n",
              " 'ser': 109,\n",
              " 'nosotros': 110,\n",
              " 'vez': 111,\n",
              " 'coche': 112,\n",
              " 'estar': 113,\n",
              " 'sos': 114,\n",
              " 'feliz': 115,\n",
              " 'va': 116,\n",
              " 'buen': 117,\n",
              " 'tarde': 118,\n",
              " 'ti': 119,\n",
              " 'ahi': 120,\n",
              " 'frances': 121,\n",
              " 'hablar': 122,\n",
              " 'hacer': 123,\n",
              " 'verdad': 124,\n",
              " 'hace': 125,\n",
              " 'creo': 126,\n",
              " 'tenemos': 127,\n",
              " 'ayuda': 128,\n",
              " 'alli': 129,\n",
              " 'boston': 130,\n",
              " 'hombre': 131,\n",
              " 'has': 132,\n",
              " 'deja': 133,\n",
              " 'vi': 134,\n",
              " 've': 135,\n",
              " 'mal': 136,\n",
              " 'alguien': 137,\n",
              " 'auto': 138,\n",
              " 'vamos': 139,\n",
              " 'si': 140,\n",
              " 'mejor': 141,\n",
              " 'siento': 142,\n",
              " 'podria': 143,\n",
              " 'podemos': 144,\n",
              " 'cuando': 145,\n",
              " 'hice': 146,\n",
              " 'vida': 147,\n",
              " 'odio': 148,\n",
              " 'dia': 149,\n",
              " 'conmigo': 150,\n",
              " 'siempre': 151,\n",
              " 'les': 152,\n",
              " 'encanta': 153,\n",
              " 'otra': 154,\n",
              " 'dejame': 155,\n",
              " 'rapido': 156,\n",
              " 'cual': 157,\n",
              " 'ustedes': 158,\n",
              " 'vino': 159,\n",
              " 'tenia': 160,\n",
              " 'puerta': 161,\n",
              " 'bueno': 162,\n",
              " 'ver': 163,\n",
              " 'hacerlo': 164,\n",
              " 'ven': 165,\n",
              " 'tambien': 166,\n",
              " 'os': 167,\n",
              " 'comer': 168,\n",
              " 'buena': 169,\n",
              " 'sus': 170,\n",
              " 'deberia': 171,\n",
              " 'dijo': 172,\n",
              " 'listo': 173,\n",
              " 'padre': 174,\n",
              " 'habitacion': 175,\n",
              " 'habla': 176,\n",
              " 'nuestro': 177,\n",
              " 'realmente': 178,\n",
              " 'ayudar': 179,\n",
              " 'queria': 180,\n",
              " 'hecho': 181,\n",
              " 'mismo': 182,\n",
              " 'nadar': 183,\n",
              " 'cansado': 184,\n",
              " 'ocupado': 185,\n",
              " 'del': 186,\n",
              " 'acabo': 187,\n",
              " 'razon': 188,\n",
              " 'grande': 189,\n",
              " 'noche': 190,\n",
              " 'gracias': 191,\n",
              " 'mira': 192,\n",
              " 'gato': 193,\n",
              " 'miedo': 194,\n",
              " 'manana': 195,\n",
              " 'acuerdo': 196,\n",
              " 'debo': 197,\n",
              " 'cama': 198,\n",
              " 'dije': 199,\n",
              " 'tus': 200,\n",
              " 'espera': 201,\n",
              " 'visto': 202,\n",
              " 'mio': 203,\n",
              " 'tal': 204,\n",
              " 'bastante': 205,\n",
              " 'alto': 206,\n",
              " 'veo': 207,\n",
              " 'ellas': 208,\n",
              " 'necesita': 209,\n",
              " 'dame': 210,\n",
              " 'idea': 211,\n",
              " 'amigos': 212,\n",
              " 'hemos': 213,\n",
              " 'quieres': 214,\n",
              " 'pareces': 215,\n",
              " 'casi': 216,\n",
              " 'estado': 217,\n",
              " 'fui': 218,\n",
              " 'hambre': 219,\n",
              " 'dio': 220,\n",
              " 'agua': 221,\n",
              " 'sabes': 222,\n",
              " 'sabia': 223,\n",
              " 'uno': 224,\n",
              " 'comida': 225,\n",
              " 'problema': 226,\n",
              " 'facil': 227,\n",
              " 'frio': 228,\n",
              " 'fuera': 229,\n",
              " 'lunes': 230,\n",
              " 'amigo': 231,\n",
              " 'duele': 232,\n",
              " 'dejo': 233,\n",
              " 'conozco': 234,\n",
              " 'estos': 235,\n",
              " 'vio': 236,\n",
              " 'madre': 237,\n",
              " 'pronto': 238,\n",
              " 'anos': 239,\n",
              " 'nino': 240,\n",
              " 'loco': 241,\n",
              " 'haz': 242,\n",
              " 'dormir': 243,\n",
              " 'libros': 244,\n",
              " 'puso': 245,\n",
              " 'mano': 246,\n",
              " 'sin': 247,\n",
              " 'television': 248,\n",
              " 'vive': 249,\n",
              " 'ojos': 250,\n",
              " 'menos': 251,\n",
              " 'cantar': 252,\n",
              " 'estuvo': 253,\n",
              " 'hora': 254,\n",
              " 'enfermo': 255,\n",
              " 'amo': 256,\n",
              " 'seguro': 257,\n",
              " 'mundo': 258,\n",
              " 'tienen': 259,\n",
              " 'pelo': 260,\n",
              " 'murio': 261,\n",
              " 'perros': 262,\n",
              " 'perdido': 263,\n",
              " 'joven': 264,\n",
              " 'compre': 265,\n",
              " 'mujer': 266,\n",
              " 'maria': 267,\n",
              " 'nombre': 268,\n",
              " 'contigo': 269,\n",
              " 'viejo': 270,\n",
              " 'hablo': 271,\n",
              " 'triste': 272,\n",
              " 'entrar': 273,\n",
              " 'espero': 274,\n",
              " 'sueno': 275,\n",
              " 'suerte': 276,\n",
              " 'necesitamos': 277,\n",
              " 'estais': 278,\n",
              " 'haciendo': 279,\n",
              " 'reloj': 280,\n",
              " 'perdi': 281,\n",
              " 'hasta': 282,\n",
              " 'momento': 283,\n",
              " 'toma': 284,\n",
              " 'tres': 285,\n",
              " 'queremos': 286,\n",
              " 'sigue': 287,\n",
              " 'viene': 288,\n",
              " 'escuela': 289,\n",
              " 'llave': 290,\n",
              " 'culpa': 291,\n",
              " 'historia': 292,\n",
              " 'vete': 293,\n",
              " 'fuerte': 294,\n",
              " 'calor': 295,\n",
              " 'vas': 296,\n",
              " 'cafe': 297,\n",
              " 'gran': 298,\n",
              " 'temprano': 299,\n",
              " 'cerca': 300,\n",
              " 'cerveza': 301,\n",
              " 'llorar': 302,\n",
              " 'irme': 303,\n",
              " 'jugar': 304,\n",
              " 'perdio': 305,\n",
              " 'ido': 306,\n",
              " 'sola': 307,\n",
              " 'venir': 308,\n",
              " 'vivo': 309,\n",
              " 'di': 310,\n",
              " 'necesitas': 311,\n",
              " 'seas': 312,\n",
              " 'hijo': 313,\n",
              " 'media': 314,\n",
              " 'cuanto': 315,\n",
              " 'leer': 316,\n",
              " 'ingles': 317,\n",
              " 'semana': 318,\n",
              " 'mia': 319,\n",
              " 'trabaja': 320,\n",
              " 'cosas': 321,\n",
              " 'gusto': 322,\n",
              " 'pagar': 323,\n",
              " 'pueden': 324,\n",
              " 'tuve': 325,\n",
              " 'han': 326,\n",
              " 'gente': 327,\n",
              " 'manos': 328,\n",
              " 'libre': 329,\n",
              " 'salir': 330,\n",
              " 'esperar': 331,\n",
              " 'estupido': 332,\n",
              " 'leche': 333,\n",
              " 'cierto': 334,\n",
              " 'lista': 335,\n",
              " 'dificil': 336,\n",
              " 'muerto': 337,\n",
              " 'llama': 338,\n",
              " 'borracho': 339,\n",
              " 'vale': 340,\n",
              " 'bebe': 341,\n",
              " 'camino': 342,\n",
              " 'duro': 343,\n",
              " 'vos': 344,\n",
              " 'estaban': 345,\n",
              " 'zapatos': 346,\n",
              " 'sea': 347,\n",
              " 'llego': 348,\n",
              " 'primero': 349,\n",
              " 'hazlo': 350,\n",
              " 'trabajar': 351,\n",
              " 'quedate': 352,\n",
              " 'comiendo': 353,\n",
              " 'decir': 354,\n",
              " 'esos': 355,\n",
              " 'minuto': 356,\n",
              " 'bicicleta': 357,\n",
              " 'pasa': 358,\n",
              " 'lado': 359,\n",
              " 'quedo': 360,\n",
              " 'asi': 361,\n",
              " 'gatos': 362,\n",
              " 'o': 363,\n",
              " 'hermana': 364,\n",
              " 'familia': 365,\n",
              " 'respuesta': 366,\n",
              " 'ayer': 367,\n",
              " 'rico': 368,\n",
              " 'divertido': 369,\n",
              " 'extrano': 370,\n",
              " 'vuelve': 371,\n",
              " 'hacia': 372,\n",
              " 'persona': 373,\n",
              " 'llamo': 374,\n",
              " 'mala': 375,\n",
              " 'ninos': 376,\n",
              " 'sombrero': 377,\n",
              " 'saben': 378,\n",
              " 'hablando': 379,\n",
              " 'quieren': 380,\n",
              " 'ama': 381,\n",
              " 'ves': 382,\n",
              " 'cabeza': 383,\n",
              " 'debe': 384,\n",
              " 'volvio': 385,\n",
              " 'malo': 386,\n",
              " 'funciona': 387,\n",
              " 'aca': 388,\n",
              " 'da': 389,\n",
              " 'chico': 390,\n",
              " 'caja': 391,\n",
              " 'queda': 392,\n",
              " 'boca': 393,\n",
              " 'telefono': 394,\n",
              " 'vuelta': 395,\n",
              " 'paso': 396,\n",
              " 'cuenta': 397,\n",
              " 'felices': 398,\n",
              " 'empezo': 399,\n",
              " 'plan': 400,\n",
              " 'juego': 401,\n",
              " 'estabas': 402,\n",
              " 'comio': 403,\n",
              " 'esperando': 404,\n",
              " 'bajo': 405,\n",
              " 'estabamos': 406,\n",
              " 'vosotros': 407,\n",
              " 'abogado': 408,\n",
              " 'cara': 409,\n",
              " 'otro': 410,\n",
              " 'lleva': 411,\n",
              " 'mintiendo': 412,\n",
              " 'inteligente': 413,\n",
              " 'hiciste': 414,\n",
              " 'edad': 415,\n",
              " 'parar': 416,\n",
              " 'deberiamos': 417,\n",
              " 'verte': 418,\n",
              " 'tenis': 419,\n",
              " 'estuve': 420,\n",
              " 'importante': 421,\n",
              " 'esposa': 422,\n",
              " 'debes': 423,\n",
              " 'sal': 424,\n",
              " 'entiendo': 425,\n",
              " 'tome': 426,\n",
              " 'ocupada': 427,\n",
              " 'encontre': 428,\n",
              " 'amor': 429,\n",
              " 'encantan': 430,\n",
              " 'vuestro': 431,\n",
              " 'secreto': 432,\n",
              " 'suficiente': 433,\n",
              " 'palabra': 434,\n",
              " 'bailar': 435,\n",
              " 'sido': 436,\n",
              " 'manzana': 437,\n",
              " 'ni': 438,\n",
              " 'nuestra': 439,\n",
              " 'cierra': 440,\n",
              " 'venga': 441,\n",
              " 'cuidado': 442,\n",
              " 'come': 443,\n",
              " 'estare': 444,\n",
              " 'ciudad': 445,\n",
              " 'podes': 446,\n",
              " 'conoces': 447,\n",
              " 'lugar': 448,\n",
              " 'profesor': 449,\n",
              " 'habia': 450,\n",
              " 'ojala': 451,\n",
              " 'queres': 452,\n",
              " 'guerra': 453,\n",
              " 'aun': 454,\n",
              " 'camisa': 455,\n",
              " 'escucha': 456,\n",
              " 'gano': 457,\n",
              " 'acaso': 458,\n",
              " 'asiento': 459,\n",
              " 'dormido': 460,\n",
              " 'equivocado': 461,\n",
              " 'leyendo': 462,\n",
              " 'odia': 463,\n",
              " 'hermano': 464,\n",
              " 'afuera': 465,\n",
              " 'hijos': 466,\n",
              " 'toda': 467,\n",
              " 'sento': 468,\n",
              " 'despierto': 469,\n",
              " 'suyo': 470,\n",
              " 'salio': 471,\n",
              " 'carne': 472,\n",
              " 'ayudo': 473,\n",
              " 'levanto': 474,\n",
              " 'dice': 475,\n",
              " 'carta': 476,\n",
              " 'carro': 477,\n",
              " 'ambos': 478,\n",
              " 'pequeno': 479,\n",
              " 'bano': 480,\n",
              " 'cuarto': 481,\n",
              " 'llaves': 482,\n",
              " 'juntos': 483,\n",
              " 'estudiar': 484,\n",
              " 'parecia': 485,\n",
              " 'mesa': 486,\n",
              " 'parte': 487,\n",
              " 'correr': 488,\n",
              " 'deje': 489,\n",
              " 'hagas': 490,\n",
              " 'lejos': 491,\n",
              " 'termino': 492,\n",
              " 'tren': 493,\n",
              " 'importa': 494,\n",
              " 'dios': 495,\n",
              " 'hare': 496,\n",
              " 'grito': 497,\n",
              " 'ganar': 498,\n",
              " 'musica': 499,\n",
              " 'broma': 500,\n",
              " 'cancion': 501,\n",
              " 'digas': 502,\n",
              " 'tipo': 503,\n",
              " 'dolor': 504,\n",
              " 'sois': 505,\n",
              " 'conocen': 506,\n",
              " 'cuantos': 507,\n",
              " 'conoce': 508,\n",
              " 'tenes': 509,\n",
              " 'policia': 510,\n",
              " 'acaba': 511,\n",
              " 'seis': 512,\n",
              " 'suena': 513,\n",
              " 'sobre': 514,\n",
              " 'antes': 515,\n",
              " 'trabajando': 516,\n",
              " 'justo': 517,\n",
              " 'ello': 518,\n",
              " 'llame': 519,\n",
              " 'herido': 520,\n",
              " 'despues': 521,\n",
              " 'enojado': 522,\n",
              " 'tuyo': 523,\n",
              " 'dentro': 524,\n",
              " 'voz': 525,\n",
              " 'trampa': 526,\n",
              " 'tuvo': 527,\n",
              " 'equipo': 528,\n",
              " 'cocinar': 529,\n",
              " 'bolsa': 530,\n",
              " 'peligro': 531,\n",
              " 'chica': 532,\n",
              " 'canadiense': 533,\n",
              " 'amiga': 534,\n",
              " 'ropa': 535,\n",
              " 'serio': 536,\n",
              " 'gordo': 537,\n",
              " 'senti': 538,\n",
              " 'ten': 539,\n",
              " 'van': 540,\n",
              " 'caminar': 541,\n",
              " 'podeis': 542,\n",
              " 'teneis': 543,\n",
              " 'venido': 544,\n",
              " 'oido': 545,\n",
              " 'listos': 546,\n",
              " 'dias': 547,\n",
              " 'boligrafo': 548,\n",
              " 'reglas': 549,\n",
              " 'doctor': 550,\n",
              " 'llorando': 551,\n",
              " 'bromeando': 552,\n",
              " 'morir': 553,\n",
              " 'idiota': 554,\n",
              " 'error': 555,\n",
              " 'usar': 556,\n",
              " 'nina': 557,\n",
              " 'volver': 558,\n",
              " 'mucha': 559,\n",
              " 'padres': 560,\n",
              " 'largo': 561,\n",
              " 'despacio': 562,\n",
              " 'segundo': 563,\n",
              " 'olvide': 564,\n",
              " 'lloro': 565,\n",
              " 'echo': 566,\n",
              " 'paciente': 567,\n",
              " 'hombres': 568,\n",
              " 'amable': 569,\n",
              " 'sentia': 570,\n",
              " 'fin': 571,\n",
              " 'encontrar': 572,\n",
              " 'escucho': 573,\n",
              " 'pescado': 574,\n",
              " 'ingenuo': 575,\n",
              " 'casado': 576,\n",
              " 'aburrido': 577,\n",
              " 'saber': 578,\n",
              " 'alla': 579,\n",
              " 'quienes': 580,\n",
              " 'mujeres': 581,\n",
              " 'taxi': 582,\n",
              " 'tanto': 583,\n",
              " 'estudiando': 584,\n",
              " 'fumar': 585,\n",
              " 'dime': 586,\n",
              " 'autobus': 587,\n",
              " 'estudiante': 588,\n",
              " 'siguio': 589,\n",
              " 'deberias': 590,\n",
              " 'esas': 591,\n",
              " 'rompio': 592,\n",
              " 'pedi': 593,\n",
              " 'banco': 594,\n",
              " 'vaya': 595,\n",
              " 'perfecto': 596,\n",
              " 'toca': 597,\n",
              " 'pie': 598,\n",
              " 'genial': 599,\n",
              " 'cambio': 600,\n",
              " 'falta': 601,\n",
              " 'anda': 602,\n",
              " 'corriendo': 603,\n",
              " 'recuerdo': 604,\n",
              " 'dicho': 605,\n",
              " 'enfadado': 606,\n",
              " 'quieras': 607,\n",
              " 'roto': 608,\n",
              " 'manzanas': 609,\n",
              " 'sera': 610,\n",
              " 'ruido': 611,\n",
              " 'conducir': 612,\n",
              " 'japones': 613,\n",
              " 'verlo': 614,\n",
              " 'gustaria': 615,\n",
              " 'llamar': 616,\n",
              " 'compro': 617,\n",
              " 'sol': 618,\n",
              " 'seria': 619,\n",
              " 'tokio': 620,\n",
              " 'cosa': 621,\n",
              " 'camara': 622,\n",
              " 'manera': 623,\n",
              " 'mantente': 624,\n",
              " 'vista': 625,\n",
              " 'vayas': 626,\n",
              " 'entra': 627,\n",
              " 'prisa': 628,\n",
              " 'comi': 629,\n",
              " 'pago': 630,\n",
              " 'cansada': 631,\n",
              " 'caliente': 632,\n",
              " 'atras': 633,\n",
              " 'fueron': 634,\n",
              " 'contento': 635,\n",
              " 'llega': 636,\n",
              " 'dejar': 637,\n",
              " 'irte': 638,\n",
              " 'cocina': 639,\n",
              " 'ayudarte': 640,\n",
              " 'pregunto': 641,\n",
              " 'medico': 642,\n",
              " 'mirando': 643,\n",
              " 'brazo': 644,\n",
              " 'matar': 645,\n",
              " 'viste': 646,\n",
              " 'tener': 647,\n",
              " 'hermanos': 648,\n",
              " 'puesto': 649,\n",
              " 'adonde': 650,\n",
              " 'empezar': 651,\n",
              " 'ningun': 652,\n",
              " 'timido': 653,\n",
              " 'abre': 654,\n",
              " 'dejalo': 655,\n",
              " 'pan': 656,\n",
              " 'escribe': 657,\n",
              " 'normal': 658,\n",
              " 'correcto': 659,\n",
              " 'mama': 660,\n",
              " 'problemas': 661,\n",
              " 'sed': 662,\n",
              " 'posible': 663,\n",
              " 'pasado': 664,\n",
              " 'habeis': 665,\n",
              " 'perder': 666,\n",
              " 'volvere': 667,\n",
              " 'turno': 668,\n",
              " 'vayamos': 669,\n",
              " 'vere': 670,\n",
              " 'sintio': 671,\n",
              " 'paga': 672,\n",
              " 'vacia': 673,\n",
              " 'cena': 674,\n",
              " 'ganas': 675,\n",
              " 'lloviendo': 676,\n",
              " 'todas': 677,\n",
              " 'dano': 678,\n",
              " 'quisiera': 679,\n",
              " 'esperanza': 680,\n",
              " 'paris': 681,\n",
              " 'aquel': 682,\n",
              " 'cualquier': 683,\n",
              " 'dar': 684,\n",
              " 'solia': 685,\n",
              " 'papel': 686,\n",
              " 'adentro': 687,\n",
              " 'luego': 688,\n",
              " 'ire': 689,\n",
              " 'sabemos': 690,\n",
              " 'quede': 691,\n",
              " 'salvo': 692,\n",
              " 'enferma': 693,\n",
              " 'rojo': 694,\n",
              " 'baja': 695,\n",
              " 'coge': 696,\n",
              " 'tuya': 697,\n",
              " 'llegado': 698,\n",
              " 'empieza': 699,\n",
              " 'pregunta': 700,\n",
              " 'mentiroso': 701,\n",
              " 'blanco': 702,\n",
              " 'irse': 703,\n",
              " 'guapa': 704,\n",
              " 'huele': 705,\n",
              " 'bus': 706,\n",
              " 'nosotras': 707,\n",
              " 'noticias': 708,\n",
              " 'nieve': 709,\n",
              " 'pego': 710,\n",
              " 'rio': 711,\n",
              " 'valiente': 712,\n",
              " 'disparo': 713,\n",
              " 'tonto': 714,\n",
              " 'limitate': 715,\n",
              " 'corazon': 716,\n",
              " 'haces': 717,\n",
              " 'viven': 718,\n",
              " 'apenas': 719,\n",
              " 'fiesta': 720,\n",
              " 'intento': 721,\n",
              " 'agradable': 722,\n",
              " 'abajo': 723,\n",
              " 'adelante': 724,\n",
              " 'espere': 725,\n",
              " 'vuelto': 726,\n",
              " 'sonrio': 727,\n",
              " 'raro': 728,\n",
              " 'caso': 729,\n",
              " 'quedar': 730,\n",
              " 'detesto': 731,\n",
              " 'hielo': 732,\n",
              " 'hago': 733,\n",
              " 'canta': 734,\n",
              " 'hicimos': 735,\n",
              " 'haga': 736,\n",
              " 'conocemos': 737,\n",
              " 'comprar': 738,\n",
              " 'unos': 739,\n",
              " 'dulce': 740,\n",
              " 'engano': 741,\n",
              " 'jefe': 742,\n",
              " 'pude': 743,\n",
              " 'tomo': 744,\n",
              " 'llevo': 745,\n",
              " 'empleo': 746,\n",
              " 'toco': 747,\n",
              " 'luz': 748,\n",
              " 'arma': 749,\n",
              " 'caballo': 750,\n",
              " 'dejes': 751,\n",
              " 'pescar': 752,\n",
              " 'tio': 753,\n",
              " 'menudo': 754,\n",
              " 'muchos': 755,\n",
              " 'verano': 756,\n",
              " 'llegar': 757,\n",
              " 'haber': 758,\n",
              " 'dientes': 759,\n",
              " 'consejo': 760,\n",
              " 'llover': 761,\n",
              " 'pidio': 762,\n",
              " 'foto': 763,\n",
              " 'torta': 764,\n",
              " 'nuestros': 765,\n",
              " 'hola': 766,\n",
              " 'vemos': 767,\n",
              " 'ponte': 768,\n",
              " 'intenta': 769,\n",
              " 'buenas': 770,\n",
              " 'terminado': 771,\n",
              " 'pasar': 772,\n",
              " 'sientate': 773,\n",
              " 'venid': 774,\n",
              " 'lee': 775,\n",
              " 'mando': 776,\n",
              " 'gratis': 777,\n",
              " 'hicieron': 778,\n",
              " 'miro': 779,\n",
              " 'debemos': 780,\n",
              " 'pero': 781,\n",
              " 'preparado': 782,\n",
              " 'nervioso': 783,\n",
              " 'vivir': 784,\n",
              " 'piensa': 785,\n",
              " 'colegio': 786,\n",
              " 'corto': 787,\n",
              " 'entro': 788,\n",
              " 'papa': 789,\n",
              " 'pajaro': 790,\n",
              " 'beso': 791,\n",
              " 'cuerda': 792,\n",
              " 'futbol': 793,\n",
              " 'caballos': 794,\n",
              " 'prefiero': 795,\n",
              " 'viendo': 796,\n",
              " 'escuchando': 797,\n",
              " 'japon': 798,\n",
              " 'eran': 799,\n",
              " 'adora': 800,\n",
              " 'escribio': 801,\n",
              " 'muerte': 802,\n",
              " 'enemigo': 803,\n",
              " 'confiar': 804,\n",
              " 'ventana': 805,\n",
              " 'fuego': 806,\n",
              " 'levanta': 807,\n",
              " 'preguntale': 808,\n",
              " 'hable': 809,\n",
              " 'lleno': 810,\n",
              " 'pajaros': 811,\n",
              " 'irnos': 812,\n",
              " 'adoro': 813,\n",
              " 'muriendo': 814,\n",
              " 'diez': 815,\n",
              " 'mire': 816,\n",
              " 'cualquiera': 817,\n",
              " 'agrada': 818,\n",
              " 'nueva': 819,\n",
              " 'contacto': 820,\n",
              " 'aire': 821,\n",
              " 'sopa': 822,\n",
              " 'atrapado': 823,\n",
              " 'cerro': 824,\n",
              " 'mayor': 825,\n",
              " 'pena': 826,\n",
              " 'paciencia': 827,\n",
              " 'ayudarme': 828,\n",
              " 'gustaba': 829,\n",
              " 'negro': 830,\n",
              " 'alta': 831,\n",
              " 'algunos': 832,\n",
              " 'peso': 833,\n",
              " 'dale': 834,\n",
              " 'nariz': 835,\n",
              " 'pienso': 836,\n",
              " 'respeto': 837,\n",
              " 'dan': 838,\n",
              " 'toques': 839,\n",
              " 'taza': 840,\n",
              " 'camion': 841,\n",
              " 'punto': 842,\n",
              " 'almuerzo': 843,\n",
              " 'dedo': 844,\n",
              " 'lapiz': 845,\n",
              " 'totalmente': 846,\n",
              " 'acerca': 847,\n",
              " 'corre': 848,\n",
              " 'quieto': 849,\n",
              " 'calvo': 850,\n",
              " 'debil': 851,\n",
              " 'cayo': 852,\n",
              " 'veia': 853,\n",
              " 'silencio': 854,\n",
              " 'arriba': 855,\n",
              " 'entonces': 856,\n",
              " 'cantando': 857,\n",
              " 'heroe': 858,\n",
              " 'soltero': 859,\n",
              " 'real': 860,\n",
              " 'ojo': 861,\n",
              " 'intentarlo': 862,\n",
              " 'verme': 863,\n",
              " 'vengo': 864,\n",
              " 'chicos': 865,\n",
              " 'azul': 866,\n",
              " 'gustas': 867,\n",
              " 'alguna': 868,\n",
              " 'necesitaba': 869,\n",
              " 'veces': 870,\n",
              " 'durmiendo': 871,\n",
              " 'monton': 872,\n",
              " 'grandes': 873,\n",
              " 'mios': 874,\n",
              " 'tarta': 875,\n",
              " 'descansar': 876,\n",
              " 'atencion': 877,\n",
              " 'claro': 878,\n",
              " 'robo': 879,\n",
              " 'encontrado': 880,\n",
              " 'escribir': 881,\n",
              " 'ley': 882,\n",
              " 'vendra': 883,\n",
              " 'treinta': 884,\n",
              " 'simplemente': 885,\n",
              " 'cinco': 886,\n",
              " 'gafas': 887,\n",
              " 'tele': 888,\n",
              " 'abierta': 889,\n",
              " 'peligroso': 890,\n",
              " 'mensaje': 891,\n",
              " 'cartas': 892,\n",
              " 'orgulloso': 893,\n",
              " 'abrir': 894,\n",
              " 'misma': 895,\n",
              " 'alegro': 896,\n",
              " 'continua': 897,\n",
              " 'ganado': 898,\n",
              " 'corrio': 899,\n",
              " 'ninguna': 900,\n",
              " 'calma': 901,\n",
              " 'ayudame': 902,\n",
              " 'mintio': 903,\n",
              " 'volar': 904,\n",
              " 'oscuro': 905,\n",
              " 'vimos': 906,\n",
              " 'hables': 907,\n",
              " 'asustado': 908,\n",
              " 'loca': 909,\n",
              " 'termina': 910,\n",
              " 'golf': 911,\n",
              " 'dudas': 912,\n",
              " 'confundido': 913,\n",
              " 'pierna': 914,\n",
              " 'abra': 915,\n",
              " 'necesitan': 916,\n",
              " 'gracioso': 917,\n",
              " 'vine': 918,\n",
              " 'primavera': 919,\n",
              " 'detras': 920,\n",
              " 'peor': 921,\n",
              " 'regalo': 922,\n",
              " 'espalda': 923,\n",
              " 'simple': 924,\n",
              " 'izquierda': 925,\n",
              " 'fuimos': 926,\n",
              " 'cuchillo': 927,\n",
              " 'traeme': 928,\n",
              " 'cambiado': 929,\n",
              " 'decision': 930,\n",
              " 'corbata': 931,\n",
              " 'crees': 932,\n",
              " 'abrio': 933,\n",
              " 'piano': 934,\n",
              " 'pasando': 935,\n",
              " 'paraguas': 936,\n",
              " 'piernas': 937,\n",
              " 'viajar': 938,\n",
              " 'completamente': 939,\n",
              " 'pelicula': 940,\n",
              " 'larga': 941,\n",
              " 'podrias': 942,\n",
              " 'creer': 943,\n",
              " 'caro': 944,\n",
              " 'abrigo': 945,\n",
              " 'hablas': 946,\n",
              " 'breve': 947,\n",
              " 'uso': 948,\n",
              " 'pagare': 949,\n",
              " 'estupendo': 950,\n",
              " 'toalla': 951,\n",
              " 'golpeo': 952,\n",
              " 'camina': 953,\n",
              " 'cruel': 954,\n",
              " 'mordio': 955,\n",
              " 'ocupados': 956,\n",
              " 'muneca': 957,\n",
              " 'deseo': 958,\n",
              " 'hermosa': 959,\n",
              " 'celoso': 960,\n",
              " 'saberlo': 961,\n",
              " 'canto': 962,\n",
              " 'bienvenido': 963,\n",
              " 'estudio': 964,\n",
              " 'culpable': 965,\n",
              " 'tenido': 966,\n",
              " 'bolso': 967,\n",
              " 'avion': 968,\n",
              " 'hambriento': 969,\n",
              " 'siente': 970,\n",
              " 'paz': 971,\n",
              " 'numero': 972,\n",
              " 'unas': 973,\n",
              " 'pelota': 974,\n",
              " 'riendo': 975,\n",
              " 'estara': 976,\n",
              " 'muertos': 977,\n",
              " 'trata': 978,\n",
              " 'viaje': 979,\n",
              " 'preocupado': 980,\n",
              " 'radio': 981,\n",
              " 'oficina': 982,\n",
              " 'lago': 983,\n",
              " 'entiende': 984,\n",
              " 'vives': 985,\n",
              " 'nacio': 986,\n",
              " 'siendo': 987,\n",
              " 'oportunidad': 988,\n",
              " 'escuche': 989,\n",
              " 'llamame': 990,\n",
              " 'entre': 991,\n",
              " 'gorda': 992,\n",
              " 'prueba': 993,\n",
              " 'profundo': 994,\n",
              " 'perfectamente': 995,\n",
              " 'llena': 996,\n",
              " 'pobre': 997,\n",
              " 'gane': 998,\n",
              " 'confia': 999,\n",
              " 'vosotras': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oS6mqluirWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e45ed56-7051-4c33-81ee-281bc4fcb58f"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
        "print(input_tensor_train[0])\n",
        "print(target_tensor_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24000 24000 6000 6000\n",
            "[  1   6  28   7  15 140 363  15   8   5   2   0   0   0   0   0]\n",
            "[  1   8  10   9 425 543   9  66   7   2   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4McPf16iuXH"
      },
      "source": [
        "# Create a tf.data datasest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lckoCvxAjj3U"
      },
      "source": [
        "The tf.data.Dataset API supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern:\n",
        "\n",
        "\n",
        "*   Create a source dataset from your input data.\n",
        "*   Apply dataset transformations to preprocess the data.\n",
        "*   Iterate over the dataset and process the elements.\n",
        "\n",
        "Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK3NE1vUityv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2680592a-d236-425e-9be2-d7d6902ba3d0"
      },
      "source": [
        "# Configuration \n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "steps_per_epoch_val = len(input_tensor_val)//BATCH_SIZE\n",
        "embedding_dim = 256  # for word embedding\n",
        "units = 1024  # dimensionality of the output space of RNN\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE) # suffle\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True) #xóa phần thừa\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(BUFFER_SIZE)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzo3ZvYpv4KE"
      },
      "source": [
        "# Basic seq2seq model: encoder and decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex8ORksZcTbV"
      },
      "source": [
        "Model groups layers into an object with training and inference features. Two ways to define tf model:\n",
        "\n",
        "![alt text](https://i.ibb.co/c8JX8Cc/tf-Model.jpg)\n",
        "\n",
        "Basic sequence to sequence model without attention:\n",
        "![alt text](https://i.ibb.co/QN0tyMp/seq2seq.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFjq9Ta3wA8F"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,  # Whether to return the last output in the output sequence, or the full sequence. \n",
        "                                   return_state=True,  # Whether to return the last state in addition to the output.\n",
        "                                   recurrent_initializer='glorot_uniform') # how to init weight\n",
        "\n",
        "  def call(self, x, hidden): # match layer in model\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4GoRSHSwScu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6627970d-ada4-47c7-cc8e-6f7f803e5a61"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape)) #shape: số mẫu, độ dài vec, số chiều word_index\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy6ualLHwYzY"
      },
      "source": [
        "# class Decoder(tf.keras.Model):\n",
        "#   def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "#     super(Decoder, self).__init__()\n",
        "#     self.batch_sz = batch_sz\n",
        "#     self.dec_units = dec_units\n",
        "#     self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "#     self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "#                                    return_sequences=True,\n",
        "#                                    return_state=True,\n",
        "#                                    recurrent_initializer='glorot_uniform')\n",
        "#     self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "\n",
        "#   def call(self, x, hidden):\n",
        "#     # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "#     x = self.embedding(x)\n",
        "\n",
        "#     # passing the concatenated vector to the GRU\n",
        "#     output, state = self.gru(x, initial_state = hidden)\n",
        "\n",
        "#     # output shape == (batch_size * 1, hidden_size)\n",
        "#     output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "#     # output shape == (batch_size, vocab)\n",
        "#     x = self.fc(output)\n",
        "#     return x, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUXzFdWhhu1D"
      },
      "source": [
        "# tf.reshape([[1,2,3],[4,5,6]], (-1, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_z9vs5U06hk"
      },
      "source": [
        "# decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample_decoder_output, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "#                                       sample_hidden)\n",
        "\n",
        "# print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBGeYTE14Oij"
      },
      "source": [
        "# Dot-product attention\n",
        "\n",
        "![alt text](https://i.ibb.co/TvhM1Z2/attention.jpg)\n",
        "\n",
        "![alt text](https://i.ibb.co/bvrcptV/dotproduct.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vqqDed3xYH-"
      },
      "source": [
        "class DotProductAttention(tf.keras.layers.Layer):\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # inner product, score shape == (batch_size, max_length, 1)\n",
        "    score = query_with_time_axis * values\n",
        "    score = tf.reduce_sum(score, axis=2)\n",
        "    score = tf.expand_dims(score, 2)\n",
        "    \n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlQqI7zA2MTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a24a75-9ff8-4c8d-a931-486358249ef5"
      },
      "source": [
        "attention_layer = DotProductAttention()\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSWViCN635g8"
      },
      "source": [
        "# Additive attention\n",
        "\n",
        "![alt text](https://i.ibb.co/BqDYNP1/additive.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1-eiiJ_xyoM"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(query_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cnv4ILg87cM"
      },
      "source": [
        "# Decoder layer with attention\n",
        "\n",
        "![alt text](https://i.ibb.co/ZM25Zvv/Context-Vector.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXqWOEGh9BAm"
      },
      "source": [
        "class DecoderWithAttention(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_layer = None):\n",
        "    super(DecoderWithAttention, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = attention_layer\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "    attention_weights = None\n",
        "    \n",
        "    if self.attention:\n",
        "      # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "      context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "      # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "      x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) #concat vector with input\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK2x4JEx1Gji"
      },
      "source": [
        "# Define loss function\n",
        "\n",
        "Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label. \n",
        "![alt text](https://i.ibb.co/GtD1vc9/cross-entropy.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9oozBiV1Khj"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none') #tính toán tổn thất chéo giữa nhãn và dự đoán\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) \n",
        "  loss_ = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFLLiTBgnwG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd02d256-ed93-4bdd-9843-7170b3f8b890"
      },
      "source": [
        "print(loss_object([1,2],[[0,0.6,0.3,0.1],[0,0.6,0.3,0.1]]))\n",
        "print(loss_function([1,2],[[0,0.6,0.3,0.1],[0,0.6,0.3,0.1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1.063386  1.3633859], shape=(2,), dtype=float32)\n",
            "tf.Tensor(1.2133859, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2NpO5aG1UDu"
      },
      "source": [
        "# Training\n",
        "\n",
        "@tf.function\n",
        "In TensorFlow 2, eager execution is turned on by default. The user interface is intuitive and flexible (running one-off operations is much easier and faster), but this can come at the expense of performance and deployability. It is recommended to debug in eager mode, then decorate with @tf.function for better performance.\n",
        "\n",
        "In TensorFlow 2.0, users should refactor their code into smaller functions which are called as needed. In general, it's not necessary to decorate each of these smaller functions with tf.function; only use tf.function to decorate high-level computations - for example, one step of training, or the forward pass of your model.\n",
        "\n",
        "TensorFlow provides the tf.GradientTape API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually tf.Variables. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz6c3l931TC8"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "# Use gradient descent\n",
        "def get_train_step_func():\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(inp, targ, enc_hidden, encoder, decoder): #input, target\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape: # for automatic differentiation\n",
        "      enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "      dec_hidden = enc_hidden # đưa hidden state vào decoder\n",
        "\n",
        "      dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "      # Teacher forcing - feeding the target as the next input\n",
        "      for t in range(1, targ.shape[1]): # đi qua từng decoder input\n",
        "        # passing enc_output to the decoder\n",
        "        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "        loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "        # using teacher forcing\n",
        "        dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n",
        "    \n",
        "  return train_step\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zym-buZ_TEg"
      },
      "source": [
        "def caculate_validation_loss(inp, targ, enc_hidden, encoder, decoder):\n",
        "  loss = 0\n",
        "  enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "  # Teacher forcing - feeding the target as the next input\n",
        "  for t in range(1, targ.shape[1]):\n",
        "    predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "    loss += loss_function(targ[:, t], predictions)\n",
        "    dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  loss = loss / int(targ.shape[1])\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMo0_PVaJiP7"
      },
      "source": [
        "def training_seq2seq(epochs, attention):\n",
        "  encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "  decoder = DecoderWithAttention(vocab_tar_size, embedding_dim, units, BATCH_SIZE, attention)\n",
        "  train_step_func = get_train_step_func()\n",
        "  training_loss = []\n",
        "  validation_loss = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "      batch_loss = train_step_func(inp, targ, enc_hidden, encoder, decoder)\n",
        "      total_loss += batch_loss\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss))\n",
        "        \n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_val_loss = 0\n",
        "    for (batch, (inp, targ)) in enumerate(validation_dataset.take(steps_per_epoch)):\n",
        "      val_loss = caculate_validation_loss(inp, targ, enc_hidden, encoder, decoder)\n",
        "      total_val_loss += val_loss\n",
        "\n",
        "    training_loss.append(total_loss / steps_per_epoch)\n",
        "    validation_loss.append(total_val_loss / steps_per_epoch_val)\n",
        "    print('Epoch {} Loss {:.4f} Validation Loss {:.4f}'.format(epoch + 1,\n",
        "                                        training_loss[-1], validation_loss[-1]))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "  return encoder, decoder, training_loss, validation_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r96cK-kAVLbG"
      },
      "source": [
        "## Training seq2seq without attention\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4knY8jaQ1gcO"
      },
      "source": [
        "# epochs = 10\n",
        "# attention = None\n",
        "\n",
        "# print(\"Running seq2seq model without attention\")\n",
        "# encoder, decoder, training_loss, validation_loss = training_seq2seq(epochs, attention)\n",
        "\n",
        "# tloss = training_loss\n",
        "# vloss = validation_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2w0wAvhVUtq"
      },
      "source": [
        "## Training seq2seq with dot product attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alodSzmpX77O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc042f9-d7d5-4f78-aa09-456668ba7067"
      },
      "source": [
        "attention = DotProductAttention()\n",
        "epochs = 10\n",
        "print(\"Running seq2seq model with dot product attention\")\n",
        "encoder_dp, decoder_dp, training_loss, validation_loss = training_seq2seq(epochs, attention)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running seq2seq model with dot product attention\n",
            "Epoch 1 Batch 0 Loss 4.7113\n",
            "Epoch 1 Batch 100 Loss 2.2252\n",
            "Epoch 1 Batch 200 Loss 1.8527\n",
            "Epoch 1 Batch 300 Loss 1.7917\n",
            "Epoch 1 Loss 2.0328 Validation Loss 1.6162\n",
            "Time taken for 1 epoch 78.5709798336029 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4792\n",
            "Epoch 2 Batch 100 Loss 1.4348\n",
            "Epoch 2 Batch 200 Loss 1.3220\n",
            "Epoch 2 Batch 300 Loss 1.3503\n",
            "Epoch 2 Loss 1.3813 Validation Loss 1.2650\n",
            "Time taken for 1 epoch 69.97269439697266 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.1551\n",
            "Epoch 3 Batch 100 Loss 1.0240\n",
            "Epoch 3 Batch 200 Loss 0.9837\n",
            "Epoch 3 Batch 300 Loss 1.0008\n",
            "Epoch 3 Loss 1.0121 Validation Loss 1.0542\n",
            "Time taken for 1 epoch 59.9301221370697 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.7454\n",
            "Epoch 4 Batch 100 Loss 0.7339\n",
            "Epoch 4 Batch 200 Loss 0.6512\n",
            "Epoch 4 Batch 300 Loss 0.6233\n",
            "Epoch 4 Loss 0.7199 Validation Loss 0.9185\n",
            "Time taken for 1 epoch 60.008312940597534 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4479\n",
            "Epoch 5 Batch 100 Loss 0.5269\n",
            "Epoch 5 Batch 200 Loss 0.4938\n",
            "Epoch 5 Batch 300 Loss 0.4540\n",
            "Epoch 5 Loss 0.4909 Validation Loss 0.8509\n",
            "Time taken for 1 epoch 59.87246489524841 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2985\n",
            "Epoch 6 Batch 100 Loss 0.3490\n",
            "Epoch 6 Batch 200 Loss 0.3118\n",
            "Epoch 6 Batch 300 Loss 0.3457\n",
            "Epoch 6 Loss 0.3253 Validation Loss 0.8210\n",
            "Time taken for 1 epoch 59.442434549331665 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.2132\n",
            "Epoch 7 Batch 100 Loss 0.1616\n",
            "Epoch 7 Batch 200 Loss 0.2046\n",
            "Epoch 7 Batch 300 Loss 0.2003\n",
            "Epoch 7 Loss 0.2122 Validation Loss 0.8285\n",
            "Time taken for 1 epoch 59.46294903755188 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1345\n",
            "Epoch 8 Batch 100 Loss 0.1332\n",
            "Epoch 8 Batch 200 Loss 0.1547\n",
            "Epoch 8 Batch 300 Loss 0.1956\n",
            "Epoch 8 Loss 0.1460 Validation Loss 0.8371\n",
            "Time taken for 1 epoch 60.1039936542511 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1217\n",
            "Epoch 9 Batch 100 Loss 0.0884\n",
            "Epoch 9 Batch 200 Loss 0.0873\n",
            "Epoch 9 Batch 300 Loss 0.1231\n",
            "Epoch 9 Loss 0.1060 Validation Loss 0.8465\n",
            "Time taken for 1 epoch 59.92691111564636 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0715\n",
            "Epoch 10 Batch 100 Loss 0.0837\n",
            "Epoch 10 Batch 200 Loss 0.0709\n",
            "Epoch 10 Batch 300 Loss 0.0985\n",
            "Epoch 10 Loss 0.0849 Validation Loss 0.8555\n",
            "Time taken for 1 epoch 59.903181314468384 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai9m4NYf-rPy"
      },
      "source": [
        "tloss = training_loss\n",
        "vloss = validation_loss\n",
        "tloss = np.vstack((tloss, training_loss))\n",
        "vloss = np.vstack((vloss, validation_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "0C7AEmyISp2P",
        "outputId": "e222867d-616e-45b5-b219-19db35a8fb9f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ax = plt.subplot(111) \n",
        "t = np.arange(1, epochs+1)\n",
        "\n",
        "for i in range(0, vloss.shape[0]):\n",
        "  line, = plt.plot(t, vloss[i,:], lw=2)\n",
        "\n",
        "ax.legend(('No attention', 'Dot product', 'Bahdanau'))\n",
        "ax.set_title(\"Validation loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Validation loss')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQKjqurFVY0u"
      },
      "source": [
        "## Training seq2seq with Bahdanau attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TUKivtyYix6"
      },
      "source": [
        "# epochs = 10\n",
        "\n",
        "# attention = BahdanauAttention(units)\n",
        "# print(\"Running seq2seq model with Bahdanau attention\")\n",
        "# encoder_bah, decoder_bah, training_loss, validation_loss = training_seq2seq(epochs, attention)\n",
        "\n",
        "# tloss = np.vstack((tloss, training_loss))\n",
        "# vloss = np.vstack((vloss, validation_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5Yk-AZ4h3Hb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "7b0fd602-7334-4bf6-fc2b-a8ba10211f97"
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# ax = plt.subplot(111) \n",
        "# t = np.arange(1, epochs+1)\n",
        "\n",
        "# for i in range(0, vloss.shape[0]):\n",
        "#   line, = plt.plot(t, vloss[i,:], lw=2)\n",
        "\n",
        "# ax.legend(('No attention', 'Dot product', 'Bahdanau'))\n",
        "# ax.set_title(\"Validation loss\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-62aad20291c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vloss' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBeMYwpMOPyI"
      },
      "source": [
        "# Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad9Fn5HrOO6i"
      },
      "source": [
        "def translate(sentence, encoder, decoder):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    # until the predicted word is <end>.\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence\n",
        "\n",
        "    # the predicted ID is fed back into the model, no teacher forcing.\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmPB_EoAWxKP"
      },
      "source": [
        "# result, sentence = translate(u'esta es mi vida.', encoder_bah, decoder_bah)\n",
        "# print('Input: %s' % (sentence))\n",
        "# print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZWVIi421_4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a0329b-54b8-498f-d442-6bf4e3cb4d1b"
      },
      "source": [
        "result, sentence = translate(u'esta es mi vida.', encoder_dp, decoder_dp)\n",
        "print('Input: %s' % (sentence))\n",
        "print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrB48Fwk7XW8"
      },
      "source": [
        "# result, sentence = translate(u'¿todavia estan en casa?', encoder_bah, decoder_bah)\n",
        "# print('Input: %s' % (sentence))\n",
        "# print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLZcz8TbR09_"
      },
      "source": [
        "# Next Steps\n",
        "\n",
        "\n",
        "*   Training on larger dataset\n",
        "*   Model tuning\n",
        "*   Try out other attention scores such as multiplicative\n",
        "*   Train on other seq2seq tasks\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}